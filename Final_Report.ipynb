{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "noticed-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import log, square, sqrt, power, arange, ones, zeros, isscalar,\\\n",
    "    array, outer, pi, sin, cos, expand_dims, repeat, full, concatenate, ravel\n",
    "from numpy.random import normal\n",
    "from scipy.optimize import least_squares, minimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "italian-startup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Trade data\n",
    "\n",
    "stock_name = 'AAPL.O'\n",
    "\n",
    "df = pd.read_csv('NSQ_OneYear100test_Sept21.csv', \n",
    "                   usecols=['Local_Date_Time','RIC','Open','High','Low','Close','VWAP','NumberOfTrades','Volume'],\n",
    "                   dtype={'Local_Date_Time': str,\n",
    "                          'RIC': str, \n",
    "                          'Open': np.float64,\n",
    "                          'High': np.float64,\n",
    "                          'Low': np.float64,\n",
    "                          'Close': np.float64,\n",
    "                          'VWAP': np.float64,\n",
    "                          'NumberOfTrades': int,\n",
    "                          'Volume': int},\n",
    "                   skipinitialspace=True,\n",
    "                   parse_dates=True)\n",
    "apple = df[df['RIC'] == stock_name]\n",
    "apple['Date'] = pd.to_datetime(apple['Local_Date_Time']).dt.date\n",
    "\n",
    "qqq = pd.read_csv('QQQ_OneYear100test_Sept21.csv', \n",
    "                   usecols=['Local_Date_Time','RIC','Open','High','Low','Close','VWAP','NumberOfTrades','Volume'],\n",
    "                   dtype={'Local_Date_Time': str,\n",
    "                          'RIC': str, \n",
    "                          'Open': np.float64,\n",
    "                          'High': np.float64,\n",
    "                          'Low': np.float64,\n",
    "                          'Close': np.float64,\n",
    "                          'VWAP': np.float64,\n",
    "                          'NumberOfTrades': int,\n",
    "                          'Volume': int},\n",
    "                   skipinitialspace=True,\n",
    "                   parse_dates=True)\n",
    "qqq['Date'] = pd.to_datetime(qqq['Local_Date_Time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "classified-certificate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Auction price data\n",
    "auction = pd.read_csv('NSQ_OneYear100closeA_Sept21.csv',\n",
    "                      skipinitialspace=True,\n",
    "                      parse_dates=True)\n",
    "apple_auction = auction[auction['RIC'] == stock_name]\n",
    "apple_auction['Date'] = pd.to_datetime(apple_auction['Local_Date_Time']).dt.date\n",
    "\n",
    "auction_qqq = pd.read_csv('QQQ_OneYear100closeA_Sept21.csv',\n",
    "                      skipinitialspace=True,\n",
    "                      parse_dates=True)\n",
    "auction_qqq['Date'] = pd.to_datetime(auction_qqq['Local_Date_Time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "offshore-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing (10 minute intervals)\n",
    "\n",
    "dates = apple['Date'].unique()\n",
    "dates_final = []\n",
    "stocks = []\n",
    "daily_return = []\n",
    "auction_log_returns = []\n",
    "auction_log_returns_340350 = []\n",
    "daily_volatility = []\n",
    "daily_volatility_minus4pm = []\n",
    "avg_20day_volatility = []\n",
    "\n",
    "for date in dates:\n",
    "    \n",
    "    apple_today = apple[apple['Date'] == date]\n",
    "    apple_auction_today = apple_auction[apple_auction['Date'] == date]\n",
    "    apple_today = apple_today.set_index(pd.DatetimeIndex(apple_today['Local_Date_Time']))\n",
    "    apple_today_10min_max = pd.DataFrame(apple_today['High'].resample(\"10T\").max())\n",
    "    apple_today_10min_min = pd.DataFrame(apple_today['Low'].resample(\"10T\").min())\n",
    "    apple_today_10min_open = pd.DataFrame(apple_today['Open'].resample(\"10T\").first())\n",
    "    apple_today_10min_close = pd.DataFrame(apple_today['Close'].resample(\"10T\").last())\n",
    "    apple_today_10min = apple_today_10min_max.join(apple_today_10min_min)\n",
    "    apple_today_10min = apple_today_10min.join(apple_today_10min_open)\n",
    "    apple_today_10min = apple_today_10min.join(apple_today_10min_close)\n",
    "    \n",
    "    # Garman and Klass Volatility formula\n",
    "    apple_today_10min['Volatility'] = np.sqrt(0.5*np.square(np.log(apple_today_10min['High']/apple_today_10min['Low'])) - (2*np.log(2)-1)*np.square(np.log(apple_today_10min['Close']/apple_today_10min['Open'])))\n",
    "#     apple_today_10min['log_returns'] = abs(np.log(apple_today_10min['Close']/apple_today_10min['Open'])) # alternate volatility formula\n",
    "    \n",
    "    volatility_today = [val for val in apple_today_10min['Volatility'].values]\n",
    "    return_today = (apple_today_10min['Close']/apple_today_10min['Open']).values\n",
    "    \n",
    "    if len(volatility_today) != 39: # Skip if there are fewer than 390 minutes of trading data\n",
    "        continue\n",
    "        \n",
    "    # Dates for which the trade data is complete\n",
    "    dates_final.append(date)\n",
    "    \n",
    "    # Change the 39th 10min interval to include the auction price (instead of close)\n",
    "    auction_volatility = np.sqrt(0.5*np.square(np.log(apple_today_10min['High'][-1]/apple_today_10min['Low'][-1])) - (2*np.log(2)-1)*np.square(np.log(apple_auction_today['Price'].iloc[0]/apple_today_10min['Open'][-1])))\n",
    "    volatility_today[-1] = auction_volatility\n",
    "    \n",
    "    # 10 minute interval volatility * number of complete trade days\n",
    "    stocks.append(volatility_today)\n",
    "    \n",
    "    # Daily raw return\n",
    "    daily_return.append(return_today)\n",
    "        \n",
    "    # Auction Volatility Information\n",
    "    auction_log_returns_today = abs(np.log(apple_auction_today['Price'].iloc[0]/apple_today_10min['Open'][-1]))\n",
    "    auction_log_returns.append(auction_log_returns_today)\n",
    "    \n",
    "    # Naive Auction Volatility Estimate (Volatility between 3:40pm and 3:50pm)\n",
    "    auction_log_returns_today_340350 = abs(np.log(apple_today_10min['Open'][-1]/apple_today_10min['Open'][-2]))\n",
    "    auction_log_returns_340350.append(auction_log_returns_today_340350)\n",
    "    \n",
    "    # Average daily volatility (later used for EWMA 20Day)\n",
    "    daily_volatility.append(sum(volatility_today))\n",
    "    daily_volatility_minus4pm.append(sum(volatility_today[:-1]))\n",
    "\n",
    "daily_return = np.array(daily_return)\n",
    "volatility_df = pd.DataFrame({'Date':dates_final, 'daily_volatility': daily_volatility, 'daily_volatility_minus4pm': daily_volatility_minus4pm})\n",
    "volatility_df['volatility_ewma20'] = np.array([None] + [i for i in volatility_df['daily_volatility'].ewm(span=20).mean()][:-1])\n",
    "\n",
    "stocks = stocks[20:]\n",
    "stocks = np.vstack(stocks).T # Training data for Anderson model\n",
    "avg_20day_volatility_raw = np.array(volatility_df['volatility_ewma20'])\n",
    "avg_20day_volatility = np.array(volatility_df['volatility_ewma20'][20:]) # Sigma_t input for Anderson model\n",
    "\n",
    "stocks200 = stocks.T\n",
    "stocks200 = stocks200[:200].T\n",
    "avg_20day_volatility200 = avg_20day_volatility[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "instant-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Processing (10 minute intervals)\n",
    "\n",
    "# dates_qqq = qqq['Date'].unique()\n",
    "# dates_final_qqq = []\n",
    "# stocks_qqq = []\n",
    "# daily_return_qqq = []\n",
    "# auction_log_returns_qqq = []\n",
    "# auction_log_returns_340350_qqq = []\n",
    "# daily_volatility_qqq = []\n",
    "# daily_volatility_minus4pm_qqq = []\n",
    "# # daily_volatility2_qqq = []\n",
    "# # daily_volatility2_minus4pm_qqq = []\n",
    "# avg_20day_volatility_qqq = []\n",
    "\n",
    "# for date in dates_qqq:\n",
    "    \n",
    "#     qqq_today = qqq[qqq['Date'] == date]\n",
    "#     qqq_auction_today = auction_qqq[auction_qqq['Date'] == date]\n",
    "#     qqq_today = qqq_today.set_index(pd.DatetimeIndex(qqq_today['Local_Date_Time']))\n",
    "#     qqq_today_10min_max = pd.DataFrame(qqq_today['High'].resample(\"10T\").max())\n",
    "#     qqq_today_10min_min = pd.DataFrame(qqq_today['Low'].resample(\"10T\").min())\n",
    "#     qqq_today_10min_open = pd.DataFrame(qqq_today['Open'].resample(\"10T\").first())\n",
    "#     qqq_today_10min_close = pd.DataFrame(qqq_today['Close'].resample(\"10T\").last())\n",
    "#     qqq_today_10min = qqq_today_10min_max.join(qqq_today_10min_min)\n",
    "#     qqq_today_10min = qqq_today_10min.join(qqq_today_10min_open)\n",
    "#     qqq_today_10min = qqq_today_10min.join(qqq_today_10min_close)\n",
    "    \n",
    "#     # Garman and Klass Volatility formula\n",
    "#     qqq_today_10min['Volatility'] = np.sqrt(0.5*np.square(np.log(qqq_today_10min['High']/qqq_today_10min['Low'])) - (2*np.log(2)-1)*np.square(np.log(qqq_today_10min['Close']/qqq_today_10min['Open'])))\n",
    "# #     qqq_today_10min['log_returns'] = abs(np.log(qqq_today_10min['Close']/qqq_today_10min['Open'])) # alternate volatility formula\n",
    "    \n",
    "#     volatility_today_qqq = qqq_today_10min['Volatility'].values\n",
    "#     return_today_qqq = (qqq_today_10min['Close']/qqq_today_10min['Open']).values\n",
    "    \n",
    "#     if len(volatility_today_qqq) != 39: # Skip if there are fewer than 390 minutes of trading data\n",
    "#         continue\n",
    "        \n",
    "#     # Dates for which the trade data is complete\n",
    "#     dates_final_qqq.append(date)\n",
    "    \n",
    "#     # Change the 39th 10min interval to include the auction price (instead of close)\n",
    "#     auction_volatility_qqq = np.sqrt(0.5*np.square(np.log(qqq_today_10min['High'][-1]/qqq_today_10min['Low'][-1])) - (2*np.log(2)-1)*np.square(np.log(qqq_auction_today['Price'].iloc[0]/qqq_today_10min['Open'][-1])))\n",
    "#     volatility_today_qqq[-1] = auction_volatility_qqq\n",
    "    \n",
    "#     # 10 minute interval volatility * number of complete trade days\n",
    "#     stocks_qqq.append(volatility_today_qqq)\n",
    "    \n",
    "#     # Daily raw return\n",
    "#     daily_return_qqq.append(return_today_qqq)\n",
    "        \n",
    "#     # Auction Volatility Information\n",
    "#     auction_log_returns_today_qqq = abs(np.log(qqq_auction_today['Price'].iloc[0]/qqq_today_10min['Open'][-1]))\n",
    "#     auction_log_returns_qqq.append(auction_log_returns_today_qqq)\n",
    "    \n",
    "#     # Naive Auction Volatility Estimate (Volatility between 3:40pm and 3:50pm)\n",
    "#     auction_log_returns_today_340350_qqq = abs(np.log(qqq_today_10min['Open'][-1]/qqq_today_10min['Open'][-2]))\n",
    "#     auction_log_returns_340350_qqq.append(auction_log_returns_today_340350_qqq)\n",
    "    \n",
    "#     # Average daily volatility (later used for EWMA 20Day)\n",
    "#     daily_volatility_qqq.append(sum(volatility_today_qqq))\n",
    "#     daily_volatility_minus4pm_qqq.append(sum(volatility_today_qqq[:-1]))\n",
    "# #     daily_volatility2_qqq.append(np.sqrt(0.5*np.square(np.log(max(qqq_today_10min['High'])/min(qqq_today_10min['Low']))) - (2*np.log(2)-1)*np.square(np.log(qqq_today_10min['Close'][-1]/qqq_today_10min['Open'][0]))))\n",
    "# #     daily_volatility2_minus4pm_qqq.append(np.sqrt(0.5*np.square(np.log(max(qqq_today_10min['High'][:-1])/min(qqq_today_10min['Low'][:-1]))) - (2*np.log(2)-1)*np.square(np.log(qqq_today_10min['Close'][-2]/qqq_today_10min['Open'][0]))))\n",
    "\n",
    "# daily_return_qqq = np.array(daily_return_qqq)\n",
    "# volatility_df_qqq = pd.DataFrame({'Date':dates_final_qqq, 'daily_volatility': daily_volatility_qqq, 'daily_volatility_minus4pm': daily_volatility_minus4pm_qqq})\n",
    "# volatility_df_qqq['volatility_ewma20'] = np.array([None] + [i for i in volatility_df_qqq['daily_volatility'].ewm(span=20).mean()][:-1])\n",
    "\n",
    "# stocks_qqq = stocks_qqq[20:]\n",
    "# stocks_qqq = np.vstack(stocks_qqq).T # Training data for Anderson model\n",
    "# avg_20day_volatility_raw_qqq = np.array(volatility_df_qqq['volatility_ewma20'])\n",
    "# avg_20day_volatility_qqq = np.array(volatility_df_qqq['volatility_ewma20'][20:]) # Sigma_t input for Anderson model\n",
    "\n",
    "# stocks_qqq = stocks_qqq.T\n",
    "# stocks200_qqq = stocks_qqq[:200].T\n",
    "# avg_20day_volatility200_qqq = avg_20day_volatility_qqq[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "third-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating beta for the stock (USE VOLATILITY TO VOLATILITY)\n",
    "# daily_beta = []\n",
    "\n",
    "# for i in range(251):\n",
    "#     today_corr = np.corrcoef(daily_return[i][:-1], daily_return_qqq[i][:-1])[1][0]\n",
    "#     today_beta = today_corr * np.sqrt(np.var(daily_return[i])) / np.sqrt(np.var(daily_return_qqq[i]))\n",
    "#     daily_beta.append(today_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "defensive-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### FOURIER STOCK ###########\n",
    "\n",
    "# fourier = flexible_fourier_regression(N=39, di=[], J=2, P=17) # 39 10-minute intervals in each trade day\n",
    "# res = fourier.train(stocks200, avg_20day_volatility200, 0.0000005)\n",
    "# print(\"optimizer success: {}\".format(res.success))\n",
    "# print(\"objective function (mse): {:.8f}\".format(res.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "exciting-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=230\n",
    "# result = fourier.predict(avg_20day_volatility[n])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(18, 8))\n",
    "# ax.plot(stocks.T[n], label=\"actual\")\n",
    "# ax.plot(result, label=\"predicted\")\n",
    "# plt.xlabel(\"10 minute Time Interval\")\n",
    "# plt.ylabel(\"Absolute Log Returns\")\n",
    "# plt.title('Actual vs. Predicted Absolute Log Returns for MSFT on 2021-08-30')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "immune-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = [None for i in range(20)]\n",
    "# results_full = []\n",
    "\n",
    "# for vol in avg_20day_volatility:\n",
    "#     result = fourier.predict(vol)\n",
    "#     results_full.append(np.array([res[0] for res in result]))\n",
    "#     results.append(result[-1][0])\n",
    "    \n",
    "# results = np.array(results)\n",
    "# results_full = np.array(results_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "expanded-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual = stocks.T[-31:,-1]\n",
    "# predicted = np.array([fourier.predict(avg_20day_volatility[n])[-1][0] for n in range(200,231)])\n",
    "# print(mean_absolute_error(actual, predicted))\n",
    "# print(mean_squared_error(actual, predicted))\n",
    "# print(r2_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "compatible-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(actual, predicted, alpha=0.5)\n",
    "# # plt.xlim([0, 0.012])\n",
    "# # plt.ylim([0, 0.012])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "logical-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(actual, label=\"actual\")\n",
    "# plt.plot(predicted, label=\"predicted\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-offering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "engaged-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=230\n",
    "\n",
    "# # After Bayes\n",
    "# bayes_dayVol = fourier.vol_update(stocks.T[n,:39], avg_20day_volatility[n], tol=1e-7)\n",
    "# bayes_result = fourier.predict(bayes_dayVol)\n",
    "\n",
    "# # Plot\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(18, 8))\n",
    "# ax.plot(stocks.T[n], label=\"actual\")\n",
    "# ax.plot(results_full[n], label=\"pred\")\n",
    "# ax.plot(bayes_result, label=\"pred_bayes\")\n",
    "# plt.xlabel(\"10 minute Time Interval\")\n",
    "# plt.ylabel(\"Absolute Log Returns\")\n",
    "# plt.title('Actual vs. Predicted Absolute Log Returns for MSFT on 2021-08-30')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "based-visitor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from copy import deepcopy\n",
    "\n",
    "# # Before Bayes\n",
    "# fourier = flexible_fourier_regression(N=39, di=[], J=2, P=17) # 39 10-minute intervals in each trade day\n",
    "# res = fourier.train(stocks200, avg_20day_volatility200, 0.0000005)\n",
    "# predicted2 = []\n",
    "\n",
    "# for n in range(200,231):\n",
    "\n",
    "#     fourier_copy = deepcopy(fourier)\n",
    "\n",
    "#     # After Bayes\n",
    "#     bayes_dayVol = fourier_copy.vol_update(stocks.T[n,:39], avg_20day_volatility[n], tol=1e-7)\n",
    "#     bayes_result = fourier_copy.predict(bayes_dayVol)\n",
    "#     predicted2.append(bayes_result[-1][0])\n",
    "\n",
    "# #     print(n)\n",
    "# #     print('Before Bayes:', abs(stocks.T[n][-1] - results_full[n][-1]))\n",
    "# #     print('After Bayes:', abs(stocks.T[n][-1] - bayes_result[-1]))\n",
    "# #     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "grand-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(actual, predicted2))\n",
    "# print(mean_squared_error(actual, predicted2))\n",
    "# print(r2_score(actual, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "sharp-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(actual, label=\"actual\")\n",
    "# plt.plot(predicted2, label=\"predicted\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-finance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "flexible-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mod2C = pd.DataFrame()\n",
    "# df_mod2C['Date'] = volatility_df['Date'][-32:]\n",
    "# df_mod2C['daily_volatility'] = volatility_df['daily_volatility'][-32:]\n",
    "# df_mod2C['daily_volatility_minus4pm'] = volatility_df['daily_volatility_minus4pm'][-32:]\n",
    "# df_mod2C['auction'] = df_mod2C['daily_volatility'] - df_mod2C['daily_volatility_minus4pm']\n",
    "# df_mod2C['daily_volatility_minus4pm_yest'] = df_mod2C['daily_volatility_minus4pm'].shift(1)\n",
    "# df_mod2C['fourier_volatility_yest'] = np.array([None] + [val for val in predicted])\n",
    "# df_mod2C['fourier_volatility_2c'] = df_mod2C['daily_volatility_minus4pm']/df_mod2C['daily_volatility_minus4pm_yest']*df_mod2C['fourier_volatility_yest']\n",
    "# df_mod2C = df_mod2C[1:]\n",
    "# df_mod2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "mounted-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted3 = df_mod2C['fourier_volatility_2c']\n",
    "\n",
    "# print(mean_absolute_error(actual, predicted3))\n",
    "# print(mean_squared_error(actual, predicted3))\n",
    "# print(r2_score(actual, predicted3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "brief-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(actual, label=\"actual\")\n",
    "# plt.plot(np.array(predicted3), label=\"predicted\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from Module.baseModule.bayesFlexibleFourier import *\n",
    "\n",
    "## Hyper-parameter tuning using first 200 days\n",
    "\n",
    "params_MAE = (0,0)\n",
    "params_MSE = (0,0)\n",
    "params_r_squared = (0,0)\n",
    "\n",
    "MAE_min = float('inf')\n",
    "MSE_min = float('inf')\n",
    "R_squared_max = -float('inf')\n",
    "\n",
    "for j in [1,2,3,4]:\n",
    "    for p in [15,17,19,21,23,25]:      \n",
    "        print('Checking for:', (j,p))\n",
    "        \n",
    "        # Train the model based on first 200 days\n",
    "        fourier = flexible_fourier_regression(N=39, di=[], J=j, P=p) # 39 10-minute intervals in each trade day\n",
    "        res = fourier.train(stocks200, avg_20day_volatility200, 0.0000005) \n",
    "\n",
    "        # Prediction on the last 31 days\n",
    "        results = fourier.predict(avg_20day_volatility[-31:])\n",
    "\n",
    "        if mean_absolute_error(stocks.T[-31:,-1], results[-1,:]) < MAE_min:\n",
    "            params_MAE = (j,p)\n",
    "            MAE_min = mean_absolute_error(stocks.T[-31:,-1], results[-1,:])\n",
    "            \n",
    "        if mean_squared_error(stocks.T[-31:,-1], results[-1,:]) < MSE_min:\n",
    "            params_MSE = (j,p)\n",
    "            MSE_min = mean_squared_error(stocks.T[-31:,-1], results[-1,:])\n",
    "            \n",
    "        if r2_score(stocks.T[-31:,-1], results[-1,:]) > R_squared_max:\n",
    "            params_r_squared = (j,p)\n",
    "            R_squared_max = r2_score(stocks.T[-31:,-1], results[-1,:])\n",
    "\n",
    "print(params_MAE)\n",
    "print(params_MSE)\n",
    "print(params_r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-regulation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-barrel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "grateful-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### FOURIER MOVING WINDOW (20Days) ###########\n",
    "\n",
    "# Data Processing (10 minute intervals)\n",
    "dates = apple['Date'].unique()\n",
    "dates_final = []\n",
    "stocks = []\n",
    "daily_return = []\n",
    "auction_log_returns = []\n",
    "auction_log_returns_340350 = []\n",
    "daily_volatility = []\n",
    "daily_volatility_minus4pm = []\n",
    "avg_20day_volatility = []\n",
    "\n",
    "for date in dates:\n",
    "    \n",
    "    apple_today = apple[apple['Date'] == date]\n",
    "    apple_auction_today = apple_auction[apple_auction['Date'] == date]\n",
    "    apple_today = apple_today.set_index(pd.DatetimeIndex(apple_today['Local_Date_Time']))\n",
    "    apple_today_10min_max = pd.DataFrame(apple_today['High'].resample(\"10T\").max())\n",
    "    apple_today_10min_min = pd.DataFrame(apple_today['Low'].resample(\"10T\").min())\n",
    "    apple_today_10min_open = pd.DataFrame(apple_today['Open'].resample(\"10T\").first())\n",
    "    apple_today_10min_close = pd.DataFrame(apple_today['Close'].resample(\"10T\").last())\n",
    "    apple_today_10min = apple_today_10min_max.join(apple_today_10min_min)\n",
    "    apple_today_10min = apple_today_10min.join(apple_today_10min_open)\n",
    "    apple_today_10min = apple_today_10min.join(apple_today_10min_close)\n",
    "    \n",
    "    # Garman and Klass Volatility formula\n",
    "    apple_today_10min['Volatility'] = np.sqrt(0.5*np.square(np.log(apple_today_10min['High']/apple_today_10min['Low'])) - (2*np.log(2)-1)*np.square(np.log(apple_today_10min['Close']/apple_today_10min['Open'])))   \n",
    "    volatility_today = [val for val in apple_today_10min['Volatility'].values]\n",
    "    \n",
    "    if len(volatility_today) != 39: # Skip if there are fewer than 390 minutes of trading data\n",
    "        continue\n",
    "        \n",
    "    # Dates for which the trade data is complete\n",
    "    dates_final.append(date)\n",
    "    \n",
    "    # Change the 39th 10min interval to include the auction price (instead of close)\n",
    "    auction_volatility = np.sqrt(0.5*np.square(np.log(apple_today_10min['High'][-1]/apple_today_10min['Low'][-1])) - (2*np.log(2)-1)*np.square(np.log(apple_auction_today['Price'].iloc[0]/apple_today_10min['Open'][-1])))\n",
    "    volatility_today[-1] = auction_volatility\n",
    "    \n",
    "    # 10 minute interval volatility * number of complete trade days\n",
    "    stocks.append(volatility_today)\n",
    "        \n",
    "    # Auction Log Return Information\n",
    "    auction_log_returns_today = abs(np.log(apple_auction_today['Price'].iloc[0]/apple_today_10min['Open'][-1]))\n",
    "    auction_log_returns.append(auction_log_returns_today)\n",
    "    \n",
    "    # Naive Auction Log Return Estimate (Volatility between 3:40pm and 3:50pm)\n",
    "    auction_log_returns_today_340350 = abs(np.log(apple_today_10min['Open'][-1]/apple_today_10min['Open'][-2]))\n",
    "    auction_log_returns_340350.append(auction_log_returns_today_340350)\n",
    "    \n",
    "    # Average daily volatility (later used for EWMA 20Day)\n",
    "    daily_volatility.append(sum(volatility_today))\n",
    "    daily_volatility_minus4pm.append(sum(volatility_today[:-1]))\n",
    "\n",
    "# daily_return = np.array(daily_return)\n",
    "volatility_df = pd.DataFrame({'Date':dates_final, 'daily_volatility': daily_volatility, 'daily_volatility_minus4pm': daily_volatility_minus4pm})\n",
    "volatility_df['volatility_ewma20'] = np.array([None] + [i for i in volatility_df['daily_volatility'].ewm(span=20).mean()][:-1])\n",
    "\n",
    "stocks = np.vstack(stocks)[20:].T # Training data for Anderson model\n",
    "avg_20day_volatility = np.array(volatility_df['volatility_ewma20'])[20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window\n",
    "\n",
    "actual_fourier_window = []\n",
    "predicted_fourier_window = []\n",
    "for i in range(211):\n",
    "    stocks_window = stocks[:,i:i+20]\n",
    "    avg_20day_volatility_window = avg_20day_volatility[i:i+20]    \n",
    "    fourier_window = flexible_fourier_regression(N=39, di=[], J=2, P=17) # 39 10-minute intervals in each trade day\n",
    "    res_window = fourier_window.train(stocks_window, avg_20day_volatility_window, 0.0000005)\n",
    "    print(\"optimizer success: {}\".format(res_window.success))\n",
    "    print(\"objective function (mse): {:.8f}\".format(res_window.fun))\n",
    "    \n",
    "    # No Bayes\n",
    "    result = fourier_window.predict(avg_20day_volatility[i+20])\n",
    "    \n",
    "    actual_fourier_window.append(stocks.T[i+20][-1])\n",
    "    predicted_fourier_window.append(result[-1][0])\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(actual_fourier_window, predicted_fourier_window))\n",
    "print(mean_squared_error(actual_fourier_window, predicted_fourier_window))\n",
    "print(r2_score(actual_fourier_window, predicted_fourier_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=30\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(18, 8))\n",
    "# ax.plot(stocks.T[i+20], label=\"actual\")\n",
    "# ax.plot(result, label=\"predicted\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(actual_fourier_window, predicted_fourier_window, alpha=0.5)\n",
    "# plt.xlabel(\"actual\")\n",
    "# plt.ylabel(\"predicted\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(actual_fourier_window, bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(predicted_fourier_window, bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window - Adaptive\n",
    "\n",
    "actual_fourier_window = []\n",
    "predicted_fourier_window = []\n",
    "for i in range(211):\n",
    "    stocks_window = stocks[:,i:i+20]\n",
    "    avg_20day_volatility_window = avg_20day_volatility[i:i+20]    \n",
    "    fourier_window = flexible_fourier_regression(N=39, di=[], J=2, P=17) # 39 10-minute intervals in each trade day\n",
    "    res_window = fourier_window.train(stocks_window, avg_20day_volatility_window, 0.0000005)\n",
    "    print(\"optimizer success: {}\".format(res_window.success))\n",
    "    print(\"objective function (mse): {:.8f}\".format(res_window.fun))\n",
    "\n",
    "    # After Bayes\n",
    "    bayes_dayVol = fourier_window.vol_update(stocks.T[i+20,:39], avg_20day_volatility[i+20], tol=1e-8)\n",
    "    result = fourier_window.predict(bayes_dayVol)\n",
    "    \n",
    "    actual_fourier_window.append(stocks.T[i+20][-1])\n",
    "    predicted_fourier_window.append(result[-1][0])\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(actual_fourier_window, predicted_fourier_window))\n",
    "print(mean_squared_error(actual_fourier_window, predicted_fourier_window))\n",
    "print(r2_score(actual_fourier_window, predicted_fourier_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-glory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window - 2C\n",
    "\n",
    "actual_fourier_window = []\n",
    "predicted_fourier_window = []\n",
    "for i in range(211):\n",
    "    stocks_window = stocks[:,i:i+20]\n",
    "    avg_20day_volatility_window = avg_20day_volatility[i:i+20]    \n",
    "    fourier_window = flexible_fourier_regression(N=39, di=[], J=2, P=17) # 39 10-minute intervals in each trade day\n",
    "    res_window = fourier_window.train(stocks_window, avg_20day_volatility_window, 0.0000005)\n",
    "    print(\"optimizer success: {}\".format(res_window.success))\n",
    "    print(\"objective function (mse): {:.8f}\".format(res_window.fun))\n",
    "    \n",
    "    # No Bayes\n",
    "    result = fourier_window.predict(avg_20day_volatility[i+20])\n",
    "    \n",
    "    actual_fourier_window.append(stocks.T[i+20][-1])\n",
    "    predicted_fourier_window.append(result[-1][0])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_df['daily_volatility_minus4pm_yest'] = volatility_df['daily_volatility_minus4pm'].shift(1)\n",
    "volatility_df['volatility_ewma20_auction_1c'] = volatility_df['daily_volatility_minus4pm']/volatility_df['daily_volatility_minus4pm_yest']*volatility_df['volatility_ewma20_auction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(actual_fourier_window, predicted_fourier_window))\n",
    "print(mean_squared_error(actual_fourier_window, predicted_fourier_window))\n",
    "print(r2_score(actual_fourier_window, predicted_fourier_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-martin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### FOURIER QQQ ###########\n",
    "\n",
    "# fourier_qqq = flexible_fourier_regression(N=39, di=[], J=3, P=15) # 39 10-minute intervals in each trade day\n",
    "# res = fourier.train(stocks200_qqq, avg_20day_volatility200_qqq, 0.0000005)\n",
    "# print(\"optimizer success: {}\".format(res.success))\n",
    "# print(\"objective function (mse): {:.8f}\".format(res.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=224\n",
    "# result = fourier.predict(avg_20day_volatility_qqq[n])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(18, 8))\n",
    "# ax.plot(stocks.T[n], label=\"actual\")\n",
    "# ax.plot(result, label=\"predicted\")\n",
    "# plt.xlabel(\"10 minute Time Interval\")\n",
    "# plt.ylabel(\"Absolute Log Returns\")\n",
    "# plt.title('Actual vs. Predicted Absolute Log Returns for MSFT on 2021-08-30')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_qqq = [None for i in range(20)]\n",
    "# results_qqq_full = []\n",
    "\n",
    "# for vol in avg_20day_volatility_qqq:\n",
    "#     result = fourier_qqq.predict(vol)\n",
    "#     results_qqq_full.append(np.array([res[0] for res in result]))\n",
    "#     results_qqq.append(result[-1][0])\n",
    "# results_qqq = np.array(results_qqq)\n",
    "# results_qqq_full = np.array(results_qqq_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simple linear regression with Anderson coefficient\n",
    "# final_df = pd.DataFrame({\n",
    "#     'Date': dates_final,     \n",
    "#     'Daily_Volatility': volatility_df['daily_volatility'],\n",
    "#     'Daily_Volatility_minus4pm': volatility_df['daily_volatility_minus4pm'],\n",
    "\n",
    "#     'Daily_Volatility_qqq': volatility_df_qqq['daily_volatility'],\n",
    "#     'Daily_Volatility_qqq_minus4pm': volatility_df_qqq['daily_volatility_minus4pm'],\n",
    "    \n",
    "#     'Avg20_Volatility': avg_20day_volatility_raw, \n",
    "#     'Avg20_Volatility_qqq': avg_20day_volatility_raw_qqq, \n",
    "    \n",
    "#     'Beta': daily_beta,\n",
    "#     'Anderson': results,\n",
    "#     'Anderson_qqq': results_qqq,\n",
    "#     'Auction_Log_Returns': auction_log_returns\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-shepherd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-article",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
